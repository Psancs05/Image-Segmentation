{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"colufs89ROMS"},"outputs":[],"source":["#Run this cell only if executing in Colab\n","!pip install git+https://github.com/tensorflow/examples.git"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ya45zdlouAaC"},"outputs":[],"source":["import os\n","import glob\n","from pathlib import Path\n","import pandas as pd\n","import time\n","import numpy as np\n","from math import ceil\n","\n","import tensorflow as tf\n","from tensorflow import keras\n","from keras.callbacks import ReduceLROnPlateau\n","from keras.callbacks import ModelCheckpoint\n","from tensorflow.keras import layers, models, Model, optimizers\n","from tensorflow.keras import regularizers\n","from keras import backend as K\n","from tensorflow_examples.models.pix2pix import pix2pix\n","from keras_preprocessing.image import ImageDataGenerator"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zywP6NABubZj"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","metadata":{"id":"fWezWfJsvCIt"},"source":["## Getting the dataset from kaggle"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vMX_OHr2JTTW"},"outputs":[],"source":["os.environ['KAGGLE_CONFIG_DIR'] = <...path to kaggle.json file>\n","%cd <...path to working directory>"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wPzCgU9Qux3o"},"outputs":[],"source":["!kaggle datasets download -d crowww/a-large-scale-fish-dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YwFhjpmVu3LA"},"outputs":[],"source":["%ls"]},{"cell_type":"markdown","metadata":{"id":"lez70968vwnn"},"source":["## Data extraction"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QRDle0MnvyBh"},"outputs":[],"source":["if not os.path.exists('Fish_Dataset'):\n","  %shell unzip a-large-scale-fish-dataset.zip -d ./\n","else:\n","  print('The dataset is already available')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7UjD0wOZz9TB"},"outputs":[],"source":["image_dir=Path('./Fish_Dataset/Fish_Dataset')\n","labels=list(image_dir.glob('**/*GT*/*.png'))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AlZ7fuk87UsZ"},"outputs":[],"source":["images = list()\n","\n","for folder in glob.glob('./Fish_Dataset/Fish_Dataset/*/**'):\n","  if not folder.endswith('GT'):\n","    path = folder+'/**'\n","    images.append(glob.glob(path))\n","\n","images = [item for sublist in images for item in sublist]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PYY5rC4a84u_"},"outputs":[],"source":["images = pd.Series(images, name='image').astype(str)\n","labels = pd.Series(labels,name='label').astype(str)\n","df = pd.concat((images, labels), axis=1)\n","df['fish_type'] = df['label'].apply(lambda x: x.split('/')[-3])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"A4E4no6OBR-w"},"outputs":[],"source":["df['fish_type'].value_counts()\n","# There 1000 images and 1000 labels for each class"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uiVL81rNCOoe"},"outputs":[],"source":["%pylab inline\n","import matplotlib.pyplot as plt\n","import matplotlib.image as mpimg\n","img = mpimg.imread(images[0])\n","imgplot = plt.imshow(img)\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"iv2Xgf2oVxqJ"},"source":["## Image preprocessing"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AKVMNGMaV0ln"},"outputs":[],"source":["train, test, val = np.split(df.sample(frac=1), [int(.7*len(df)), int(.9*len(df))])\n","print('There are %d samples of training, %d of test and %d of validation' %(train.shape[0], test.shape[0], val.shape[0]))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9-joYKpLYyag"},"outputs":[],"source":["BATCH_SIZE = 128\n","IMG_HEIGHT = 128\n","IMG_WIDTH = 128\n","CHANNELS = 3"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1i3qVMXcYWzp"},"outputs":[],"source":["datagen_train_x = ImageDataGenerator(rescale=1./255.)\n","datagen_test_x = ImageDataGenerator(rescale=1./255.)\n","datagen_val_x = ImageDataGenerator(rescale=1./255.)\n","\n","datagen_train_y = ImageDataGenerator(rescale=1./255.)\n","datagen_test_y = ImageDataGenerator(rescale=1./255.)\n","datagen_val_y = ImageDataGenerator(rescale=1./255.)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ff7_yKVSdEm4"},"outputs":[],"source":["#! IMPORTANT: These generators contains the train/test image and the label of the img (oneHotEncoded 0->9). We want the images, but the labels are NOT IMPORTANT\n","\n","print('----- X IMAGES -----')\n","x_train_generator=datagen_train_x.flow_from_dataframe(\n","  dataframe=train,\n","  x_col=\"image\",\n","  y_col=\"fish_type\",\n","  batch_size=BATCH_SIZE,\n","  seed=42,\n","  shuffle=False,\n","  target_size=(IMG_HEIGHT,IMG_WIDTH)\n",")\n","\n","x_test_generator=datagen_test_x.flow_from_dataframe(\n","  dataframe=test,\n","  x_col=\"image\",\n","  y_col=\"fish_type\",\n","  batch_size=BATCH_SIZE,\n","  seed=42,\n","  shuffle=False,\n","  target_size=(IMG_HEIGHT,IMG_WIDTH)\n",")\n","\n","x_val_generator=datagen_val_x.flow_from_dataframe(\n","  dataframe=val,\n","  x_col=\"image\",\n","  y_col=\"fish_type\",\n","  batch_size=BATCH_SIZE,\n","  seed=42,\n","  shuffle=False,\n","  target_size=(IMG_HEIGHT,IMG_WIDTH)\n",")\n","\n","print()\n","print('----- Y IMAGES -----')\n","y_train_generator=datagen_train_y.flow_from_dataframe(\n","  dataframe=train,\n","  x_col=\"label\",\n","  y_col=\"fish_type\",\n","  batch_size=BATCH_SIZE,\n","  seed=42,\n","  shuffle=False,\n","  target_size=(IMG_HEIGHT,IMG_WIDTH)\n",")\n","\n","y_test_generator=datagen_test_y.flow_from_dataframe(\n","  dataframe=test,\n","  x_col=\"label\",\n","  y_col=\"fish_type\",\n","  batch_size=BATCH_SIZE,\n","  seed=42,\n","  shuffle=False,\n","  target_size=(IMG_HEIGHT,IMG_WIDTH)\n",")\n","\n","y_val_generator=datagen_val_y.flow_from_dataframe(\n","  dataframe=val,\n","  x_col=\"label\",\n","  y_col=\"fish_type\",\n","  batch_size=BATCH_SIZE,\n","  seed=42,\n","  shuffle=False,\n","  target_size=(IMG_HEIGHT,IMG_WIDTH)\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RFIhq0p4eidY"},"outputs":[],"source":["# for image_batch, labels_batch in y_val_generator:\n","#   print(image_batch.shape)\n","#   print(labels_batch.shape)\n","#   break"]},{"cell_type":"markdown","metadata":{"id":"ZuT2t-GYJm-Z"},"source":["## Model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"u-_lpBhoJofp"},"outputs":[],"source":["base_model = tf.keras.applications.MobileNetV2(input_shape=[IMG_HEIGHT, IMG_WIDTH, CHANNELS], include_top=False)\n","\n","#Use the activations of these layers\n","layer_names = [\n","    'block_1_expand_relu',  #64x64\n","    'block_3_expand_relu',  #32x32\n","    'block_6_expand_relu',  #16x16\n","    'block_13_expand_relu', #8x8\n","    'block_16_project',     #4x4\n","]\n","\n","base_model_outputs = [base_model.get_layer(name).output for name in layer_names]\n","\n","#Create a feature extraction model\n","down_stack = tf.keras.Model(inputs=base_model.input, outputs=base_model_outputs)\n","down_stack.trainable = False"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lg74unC2QrJZ"},"outputs":[],"source":["up_stack = [\n","    pix2pix.upsample(512, 3), #4x4 -> 8x8\n","    pix2pix.upsample(256, 3), #8x8 -> 16x16\n","    pix2pix.upsample(128, 3), #16x16 -> 32x32\n","    pix2pix.upsample(64, 3),  #32x32 -> 64x64\n","]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"e1pYBj5VRFc5"},"outputs":[],"source":["def unet_model(output_channels):\n","  inputs = tf.keras.layers.Input(shape=[IMG_HEIGHT, IMG_WIDTH, CHANNELS])\n","\n","  #Downsampling through the model\n","  skips = down_stack(inputs)\n","  x = skips[-1]\n","  skips = reversed(skips[:-1])\n","\n","  #Upsampling ans establishing the skip connections\n","  for up, skip in zip(up_stack, skips):\n","    x = up(x)\n","    concat = tf.keras.layers.Concatenate()\n","    x = concat([x, skip])\n","\n","  #This is the last layer of the model\n","  last = tf.keras.layers.Conv2DTranspose(\n","      filters=output_channels,\n","      kernel_size=3,\n","      strides=2,\n","      padding='same'\n","  ) #64x64 -> 128x128\n","\n","  x = last(x)\n","  return tf.keras.Model(inputs=inputs, outputs=x)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XC4wG1fzS6-U"},"outputs":[],"source":["OUTPUT_CHANNELS = 3\n","\n","model = unet_model(output_channels=OUTPUT_CHANNELS)\n","\n","model.compile(\n","    optimizer='adam',\n","    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n","    metrics=['accuracy']\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tqy2qD20TMfg"},"outputs":[],"source":["tf.keras.utils.plot_model(model, show_shapes=True)"]},{"cell_type":"markdown","metadata":{"id":"WXM0fd2SJpTX"},"source":["## Training loop"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"td-bq4VmJrRA"},"outputs":[],"source":["optimizer = keras.optimizers.Adam(learning_rate=1e-4)\n","loss_fn = keras.losses.MeanAbsoluteError()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6rRRByEsKGbh"},"outputs":[],"source":["@tf.function\n","def train_step(X, y):\n","  with tf.GradientTape() as tape:\n","    logits = model(X, training=True)\n","    loss_value = loss_fn(y, logits)\n","  grads = tape.gradient(loss_value, model.trainable_weights)\n","\n","  optimizer.apply_gradients(zip(grads, model.trainable_weights))\n","\n","  return loss_value\n","\n","\n","@tf.function\n","def test_step(X, y):\n","  val_logits = model(X, training=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OD0PgY_txuZR"},"outputs":[],"source":["epochs = 10\n","step_size_train = ceil(x_train_generator.n / x_train_generator.batch_size)\n","step_size_test = ceil(x_test_generator.n / x_test_generator.batch_size)\n","step_size_val = ceil(x_val_generator.n / x_val_generator.batch_size)\n","\n","\n","\n","for epoch in range(epochs):\n","  print('\\nStart of epoch %d' %(epoch+1))\n","  start_time = time.time()\n","\n","  #Iterate over the dataset with batches\n","  for step in range(int(step_size_train)):\n","    x_batch_train = next(iter(x_train_generator))[0]\n","    y_batch_train = next(iter(y_train_generator))[0]\n","\n","    loss_value = train_step(x_batch_train, y_batch_train)\n","    if step % 2 == 0:\n","      print('Training loss (for one batch) at step %d: %.4f' %(step, tf.reduce_sum(loss_value)))\n","      print('Seen so far: %s samples' %((step+1) * BATCH_SIZE))\n","\n","  # #Run a validation loop at the end of each epoch\n","  # for x_batch_val, y_batch_val in dataset_val:\n","  #   test_step(x_batch_val, y_batch_val)\n","\n","print('Time taken: %.2fs' %(time.time() - start_time))"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyPmVXjrb0aYViYitZAvvb+7","collapsed_sections":[],"name":"Fish-Segmentation.ipynb","provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
