{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"colufs89ROMS"},"outputs":[],"source":["#Run this cell only if executing in Colab\n","!pip install git+https://github.com/tensorflow/examples.git"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ya45zdlouAaC"},"outputs":[],"source":["import os\n","import glob\n","from pathlib import Path\n","import pandas as pd\n","import time\n","\n","import tensorflow as tf\n","from tensorflow import keras\n","from keras.callbacks import ReduceLROnPlateau\n","from keras.callbacks import ModelCheckpoint\n","from tensorflow.keras import layers, models, Model, optimizers\n","from tensorflow.keras import regularizers\n","from keras import backend as K\n","from tensorflow_examples.models.pix2pix import pix2pix"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zywP6NABubZj"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","metadata":{"id":"fWezWfJsvCIt"},"source":["## Getting the dataset from kaggle"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vMX_OHr2JTTW"},"outputs":[],"source":["os.environ['KAGGLE_CONFIG_DIR'] = <...path to kaggle.json file>\n","%cd <...path to working directory>"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wPzCgU9Qux3o"},"outputs":[],"source":["!kaggle datasets download -d crowww/a-large-scale-fish-dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YwFhjpmVu3LA"},"outputs":[],"source":["%ls"]},{"cell_type":"markdown","metadata":{"id":"lez70968vwnn"},"source":["## Data extraction"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QRDle0MnvyBh"},"outputs":[],"source":["if not os.path.exists('Fish_Dataset'):\n","  %shell unzip a-large-scale-fish-dataset.zip -d ./\n","else:\n","  print('The dataset is already available')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7UjD0wOZz9TB"},"outputs":[],"source":["image_dir=Path('./Fish_Dataset/Fish_Dataset')\n","labels=list(image_dir.glob('**/*GT*/*.png'))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AlZ7fuk87UsZ"},"outputs":[],"source":["images = list()\n","\n","for folder in glob.glob('./Fish_Dataset/Fish_Dataset/*/**'):\n","  if not folder.endswith('GT'):\n","    path = folder+'/**'\n","    images.append(glob.glob(path))\n","\n","images = [item for sublist in images for item in sublist]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PYY5rC4a84u_"},"outputs":[],"source":["images = pd.Series(images, name='image').astype(str)\n","labels = pd.Series(labels,name='label').astype(str)\n","df = pd.concat((images, labels), axis=1)\n","df['fish_type'] = df['label'].apply(lambda x: x.split('/')[-3])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"A4E4no6OBR-w"},"outputs":[],"source":["df['fish_type'].value_counts()\n","# There 1000 images and 1000 labels for each class"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uiVL81rNCOoe"},"outputs":[],"source":["%pylab inline\n","import matplotlib.pyplot as plt\n","import matplotlib.image as mpimg\n","img = mpimg.imread(images[0])\n","imgplot = plt.imshow(img)\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"ZuT2t-GYJm-Z"},"source":["## Model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"X_eT1DumRdyr"},"outputs":[],"source":["#TODO: Reshape the images\n","IMG_SHAPE = [128, 128, 3]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"u-_lpBhoJofp"},"outputs":[],"source":["base_model = tf.keras.applications.MobileNetV2(input_shape=IMG_SHAPE, include_top=False)\n","\n","#Use the activations of these layers\n","layer_names = [\n","    'block_1_expand_relu',  #64x64\n","    'block_3_expand_relu',  #32x32\n","    'block_6_expand_relu',  #16x16\n","    'block_13_expand_relu', #8x8\n","    'block_16_project',     #4x4\n","]\n","\n","base_model_outputs = [base_model.get_layer(name).output for name in layer_names]\n","\n","#Create a feature extraction model\n","down_stack = tf.keras.Model(inputs=base_model.input, outputs=base_model_outputs)\n","down_stack.trainable = False"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lg74unC2QrJZ"},"outputs":[],"source":["up_stack = [\n","    pix2pix.upsample(512, 3), #4x4 -> 8x8\n","    pix2pix.upsample(256, 3), #8x8 -> 16x16\n","    pix2pix.upsample(128, 3), #16x16 -> 32x32\n","    pix2pix.upsample(64, 3),  #32x32 -> 64x64\n","]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"e1pYBj5VRFc5"},"outputs":[],"source":["def unet_model(output_channels):\n","  inputs = tf.keras.layers.Input(shape=IMG_SHAPE)\n","\n","  #Downsampling through the model\n","  skips = down_stack(inputs)\n","  x = skips[-1]\n","  skips = reversed(skips[:-1])\n","\n","  #Upsampling ans establishing the skip connections\n","  for up, skip in zip(up_stack, skips):\n","    x = up(x)\n","    concat = tf.keras.layers.Concatenate()\n","    x = concat([x, skip])\n","\n","  #This is the last layer of the model\n","  last = tf.keras.layers.Conv2DTranspose(\n","      filters=output_channels,\n","      kernel_size=3,\n","      strides=2,\n","      padding='same'\n","  ) #64x64 -> 128x128\n","\n","  x = last(x)\n","  return tf.keras.Model(inputs=inputs, outputs=x)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XC4wG1fzS6-U"},"outputs":[],"source":["OUTPUT_CHANNELS = 3\n","\n","model = unet_model(output_channels=OUTPUT_CHANNELS)\n","\n","model.compile(\n","    optimizer='adam',\n","    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n","    metrics=['accuracy']\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tqy2qD20TMfg"},"outputs":[],"source":["tf.keras.utils.plot_model(model, show_shapes=True)"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyNFW7p/pUl6VZ4Kg8I60OmI","collapsed_sections":[],"name":"Fish-Segmentation.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
